{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we'll first be loading the FC matrices and explore their structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using read_dataset from Datasets/FC/create_dataset.py to read the dataset\n",
    "from Datasets.FC.create_dataset import read_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = read_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[116, 116], edge_index=[2, 1016], edge_attr=[1016, 1], y=[1])\n",
      "['edge_index', 'y', 'x', 'edge_attr']\n",
      "ValuesView({'x': tensor([[ 0.0000,  0.4543,  0.2477,  ...,  0.1753,  0.2247, -0.1751],\n",
      "        [ 0.4543,  0.0000, -0.2204,  ..., -0.1947, -0.2258, -0.1434],\n",
      "        [ 0.2477, -0.2204,  0.0000,  ..., -0.0521, -0.0804, -0.2025],\n",
      "        ...,\n",
      "        [ 0.1753, -0.1947, -0.0521,  ...,  0.0000,  0.6875, -0.1364],\n",
      "        [ 0.2247, -0.2258, -0.0804,  ...,  0.6875,  0.0000,  0.0929],\n",
      "        [-0.1751, -0.1434, -0.2025,  ..., -0.1364,  0.0929,  0.0000]]), 'edge_index': tensor([[  0,   0,   0,  ..., 114, 115, 115],\n",
      "        [  1,  10,  12,  ..., 113,  94, 109]]), 'edge_attr': tensor([[0.4543],\n",
      "        [0.5913],\n",
      "        [0.4224],\n",
      "        ...,\n",
      "        [0.6875],\n",
      "        [0.4846],\n",
      "        [0.5437]]), 'y': tensor([0])})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1099"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ok, let's explore the data a bit more\n",
    "#dataset is a list object of torch_geometric.data objects\n",
    "\n",
    "#let's see the first element\n",
    "print(dataset[0])\n",
    "\n",
    "#it's a dictionary object, let's see the keys\n",
    "print(dataset[0].keys())\n",
    "\n",
    "#ok, let's see the values\n",
    "print(dataset[0].values())\n",
    "\n",
    "#it has 4 keys, 'x', 'edge_index', 'edge_attr' and 'y' where y=0 menas the patient is healthy and y=1 means the patient has Autism Spectrum Disorder (ASD)\n",
    "\"\"\"graph = Data(x=ROI.reshape(-1,116).float(),\n",
    "                     edge_index=G.indices().reshape(2,-1).long(),\n",
    "                     edge_attr=G.values().reshape(-1,1).float(),\n",
    "                     y=y.long())\"\"\"\n",
    "\n",
    "#how much data do we have?\n",
    "len(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tpelletreaudur/.local/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "/home/tpelletreaudur/.local/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "/home/tpelletreaudur/.local/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "/home/tpelletreaudur/.local/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "/home/tpelletreaudur/.local/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "#set the seed\n",
    "import torch\n",
    "torch.manual_seed(37)\n",
    "\n",
    "DATASET = \"FC\"\n",
    "\n",
    "MODEL = \"GIN\"\n",
    "from models.models_FC import GIN_framework as framework # import the model\n",
    "gnn = framework(dataset)\n",
    "\n",
    "MODELbis = \"GINbis\"\n",
    "from models.models_FC import GIN_framework_bis as framework # import the model\n",
    "gnnbis = framework(dataset)\n",
    "\n",
    "MODELtri = \"GINtri\"\n",
    "from models.models_FC import GIN_framework_tri as framework # import the model\n",
    "gnntri = framework(dataset)\n",
    "\n",
    "MODEL2 = \"GIN2\"\n",
    "from models.models_FC import GIN_framework2 as framework2 # import the model\n",
    "gnn2 = framework2(dataset)\n",
    "\n",
    "MODEL3 = \"GIN3\"\n",
    "from models.models_FC import GIN_framework3 as framework3 # import the model\n",
    "gnn3 = framework3(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gnn.iterate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gnnbis.iterate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gnntri.iterate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gnn2.iterate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gnn3.iterate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gnn3.cross_validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gnn.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model \n",
    "# gnn.save_model(path=\"models/\"+DATASET+\"_\"+MODEL+\"server.pt\")\n",
    "\n",
    "# gnnbis.save_model(path=\"models/\"+DATASET+\"_\"+MODELbis+\"server.pt\")\n",
    "\n",
    "# gnntri.save_model(path=\"models/\"+DATASET+\"_\"+MODELtri+\"server.pt\")\n",
    "\n",
    "# gnn2.save_model(path=\"models/\"+DATASET+\"_\"+MODEL2+\"server.pt\")\n",
    "\n",
    "# gnn3.save_model(path=\"models/\"+DATASET+\"_\"+MODEL3+\"server.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the model\n",
    "gnn.load_model(path=\"models/\"+DATASET+\"_\"+MODEL+\"server.pt\", map_location=torch.device('cpu'))\n",
    "\n",
    "gnn2.load_model(path=\"models/\"+DATASET+\"_\"+MODEL2+\"server.pt\", map_location=torch.device('cpu'))\n",
    "\n",
    "gnn3.load_model(path=\"models/\"+DATASET+\"_\"+MODEL3+\"server.pt\", map_location=torch.device('cpu'))\n",
    "\n",
    "gnnbis.load_model(path=\"models/\"+DATASET+\"_\"+MODELbis+\"server.pt\", map_location=torch.device('cpu'))\n",
    "\n",
    "gnntri.load_model(path=\"models/\"+DATASET+\"_\"+MODELtri+\"server.pt\", map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 2.040, Train Acc: 0.999 Test Acc: 0.636\n"
     ]
    }
   ],
   "source": [
    "gnn.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.525, Train Acc: 0.998 Test Acc: 0.655\n"
     ]
    }
   ],
   "source": [
    "gnnbis.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 2.643, Train Acc: 1.000 Test Acc: 0.509\n"
     ]
    }
   ],
   "source": [
    "gnntri.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 2.830, Train Acc: 1.000 Test Acc: 0.586\n"
     ]
    }
   ],
   "source": [
    "gnn2.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.691, Loss: 1.036\n"
     ]
    }
   ],
   "source": [
    "gnn3.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GIN3'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL = MODEL3\n",
    "MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch_geometric.data import DataLoader\n",
    "# test_loader = DataLoader(dataset[gnn.test_idx], batch_size=1, shuffle=False)\n",
    "\n",
    "# gnn3.evaluate2(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, test_features = gnn3.evaluate_with_features2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1044, 55)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(train_features[0]))\n",
    "len(train_features), len(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "def calculate_avg_path_length(G):\n",
    "    if nx.is_connected(G):\n",
    "        return nx.average_shortest_path_length(G)\n",
    "    else:\n",
    "        # Alternative metrics for disconnected graphs\n",
    "        # Option 1: Use the average path length of the largest connected component\n",
    "        components = [G.subgraph(c).copy() for c in nx.connected_components(G)]\n",
    "        largest_component = max(components, key=len)\n",
    "        return nx.average_shortest_path_length(largest_component)\n",
    "    \n",
    "\n",
    "def compute_graph_properties(data):\n",
    "    properties = []\n",
    "    for graph_data in data:\n",
    "        G = nx.from_edgelist(graph_data.edge_index.t().tolist())\n",
    "        num_nodes = G.number_of_nodes()\n",
    "        num_edges = G.number_of_edges()\n",
    "        density = nx.density(G)\n",
    "        avg_path_len = calculate_avg_path_length(G)\n",
    "        num_cliques = len(list(nx.find_cliques(G)))\n",
    "        num_triangles = sum(nx.triangles(G).values()) / 3\n",
    "        num_squares = sum(nx.square_clustering(G).values()) / 4\n",
    "        number_of_node_in_the_largest_fully_connected_component = len(max(nx.connected_components(G), key=len))\n",
    "        small_world = nx.algorithms.smallworld.sigma(G)\n",
    "\n",
    "        properties.append((num_nodes, num_edges, density, avg_path_len, num_cliques, num_triangles, num_squares, number_of_node_in_the_largest_fully_connected_component, small_world))\n",
    "    return properties\n",
    "\n",
    "train_idx_list = gnn.train_idx.tolist()\n",
    "selected_dataset = [gnn.dataset[i] for i in train_idx_list]\n",
    "train_properties = compute_graph_properties(selected_dataset)\n",
    "test_idx_list = gnn.test_idx.tolist()\n",
    "selected_dataset = [gnn.dataset[i] for i in test_idx_list]\n",
    "test_properties = compute_graph_properties(selected_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_properties))\n",
    "train_properties[0:5]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "#save the properties in a file\n",
    "with open(\"results/\"+DATASET+\"_\"+MODEL+\"_train_properties.pkl\", \"wb\") as f:\n",
    "    pkl.dump(train_properties, f)\n",
    "\n",
    "with open(\"results/\"+DATASET+\"_\"+MODEL+\"_test_properties.pkl\", \"wb\") as f:\n",
    "    pkl.dump(test_properties, f)\n",
    "\n",
    "#load the properties\n",
    "with open(\"results/\"+DATASET+\"_\"+MODEL+\"_train_properties.pkl\", \"rb\") as f:\n",
    "    train_properties = pkl.load(f)\n",
    "\n",
    "with open(\"results/\"+DATASET+\"_\"+MODEL+\"_test_properties.pkl\", \"rb\") as f:\n",
    "    test_properties = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The embeddings of GIN are like this:\n",
    "return F.log_softmax(x7, dim=-1), (x1, x2, x3, x4, x5, x_global, x6, x7, x8)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "output_size = 1  # Predicting one property at a time\n",
    "# Define the linear model\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# Assume we have already evaluated to get features\n",
    "# train_features, test_features = gnn.evaluate_with_features2()\n",
    "\n",
    "# Extract x embeddings\n",
    "train_x = np.array([feat[0] for feat in train_features])\n",
    "test_x = np.array([feat[0] for feat in test_features])\n",
    "\n",
    "# Extract 2, 3, 4, global, 5, 6, 7 embeddings\n",
    "train_x2 = np.array([feat[1] for feat in train_features])\n",
    "test_x2 = np.array([feat[1] for feat in test_features])\n",
    "\n",
    "train_x3 = np.array([feat[2] for feat in train_features])\n",
    "test_x3 = np.array([feat[2] for feat in test_features])\n",
    "\n",
    "train_x4 = np.array([feat[3] for feat in train_features])\n",
    "test_x4 = np.array([feat[3] for feat in test_features])\n",
    "\n",
    "train_x5 = np.array([feat[4] for feat in train_features])\n",
    "test_x5 = np.array([feat[4] for feat in test_features])\n",
    "\n",
    "train_x_global = np.array([feat[5] for feat in train_features])\n",
    "test_x_global = np.array([feat[5] for feat in test_features])\n",
    "\n",
    "train_x6 = np.array([feat[6] for feat in train_features])\n",
    "test_x6 = np.array([feat[6] for feat in test_features])\n",
    "\n",
    "train_x7 = np.array([feat[7] for feat in train_features])\n",
    "test_x7 = np.array([feat[7] for feat in test_features])\n",
    "\n",
    "train_x8 = np.array([feat[8] for feat in train_features])\n",
    "test_x8 = np.array([feat[8] for feat in test_features])\n",
    "\n",
    "\n",
    "# Compute graph properties\n",
    "# train_properties = compute_graph_properties(gnn.dataset[gnn.train_idx])\n",
    "# test_properties = compute_graph_properties(gnn.dataset[gnn.test_idx])\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "train_x = torch.tensor(train_x, dtype=torch.float32)\n",
    "train_x2 = torch.tensor(train_x2, dtype=torch.float32)\n",
    "train_x3 = torch.tensor(train_x3, dtype=torch.float32)\n",
    "train_x4 = torch.tensor(train_x4, dtype=torch.float32)\n",
    "train_x5 = torch.tensor(train_x5, dtype=torch.float32)\n",
    "train_x_global = torch.tensor(train_x_global, dtype=torch.float32)\n",
    "train_x6 = torch.tensor(train_x6, dtype=torch.float32)\n",
    "train_x7 = torch.tensor(train_x7, dtype=torch.float32)\n",
    "train_x8 = torch.tensor(train_x8, dtype=torch.float32)\n",
    "\n",
    "test_x = torch.tensor(test_x, dtype=torch.float32)\n",
    "test_x2 = torch.tensor(test_x2, dtype=torch.float32)\n",
    "test_x3 = torch.tensor(test_x3, dtype=torch.float32)\n",
    "test_x4 = torch.tensor(test_x4, dtype=torch.float32)\n",
    "test_x_global = torch.tensor(test_x_global, dtype=torch.float32)\n",
    "test_x5 = torch.tensor(test_x5, dtype=torch.float32)\n",
    "test_x6 = torch.tensor(test_x6, dtype=torch.float32)\n",
    "test_x7 = torch.tensor(test_x7, dtype=torch.float32)\n",
    "test_x8 = torch.tensor(test_x8, dtype=torch.float32)\n",
    "\n",
    "train_y = torch.tensor(train_properties, dtype=torch.float32)\n",
    "test_y = torch.tensor(test_properties, dtype=torch.float32)\n",
    "\n",
    "# Train and evaluate a model for each graph property and each embedding\n",
    "property_names = ['num_nodes', 'num_edges', 'density', 'avg_path_len', 'num_cliques', 'num_triangles', 'num_squares', 'number_of_nodes_in_the_largest_fully_connected_component']\n",
    "embeddings = [(train_x, test_x), (train_x2, test_x2), (train_x3, test_x3), (train_x4, test_x4), (train_x5, test_x5), (train_x_global, test_x_global), (train_x6, test_x6), (train_x7, test_x7), (train_x8, test_x8)]\n",
    "embeddings_names = ['x1', 'x2', 'x3', 'x4', 'x5', 'x_global',  'x6', 'x7', 'x8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dictionary where we will sotre the results for each embeddings, each property\n",
    "results = {}\n",
    "\n",
    "ii = 0\n",
    "\n",
    "for train_embedding, test_embedding in embeddings:\n",
    "    input_size = train_embedding.shape[1]\n",
    "\n",
    "    for i, property_name in enumerate(property_names):\n",
    "        model = LinearModel(input_size, output_size)\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "        num_epochs = 100000  # Adjust this as needed\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(train_embedding).squeeze()\n",
    "            target = train_y[:, i].squeeze()\n",
    "\n",
    "            loss = criterion(outputs, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (epoch+1) % 1000 == 0:  # Adjust this for more frequent/lower print frequency\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}], Property: {property_name}, Loss: {loss.item():.4f}')\n",
    "\n",
    "        # Evaluate the model\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            train_pred = model(train_embedding).squeeze().cpu().numpy()\n",
    "            test_pred = model(test_embedding).squeeze().cpu().numpy()\n",
    "\n",
    "            train_target = train_y[:, i].cpu().numpy()\n",
    "            test_target = test_y[:, i].cpu().numpy()\n",
    "\n",
    "            train_mse = mean_squared_error(train_target, train_pred)\n",
    "            test_mse = mean_squared_error(test_target, test_pred)\n",
    "\n",
    "            train_r2 = r2_score(train_target, train_pred)\n",
    "            test_r2 = r2_score(test_target, test_pred)\n",
    "\n",
    "            print(f'Embedding: {train_embedding.shape}')\n",
    "            print(f'Property: {property_name}')\n",
    "            print(f'  Train MSE: {train_mse:.4f}, Test MSE: {test_mse:.4f}')\n",
    "            print(f'  Train R²: {train_r2:.4f}, Test R²: {test_r2:.4f}')\n",
    "\n",
    "            #add the results to the dictionary\n",
    "            name_of_embdedding = embeddings_names[ii]\n",
    "            results[(name_of_embdedding, property_name)] = (train_mse, test_mse, train_r2, test_r2)\n",
    "\n",
    "    ii += 1\n",
    "\n",
    "#save results\n",
    "with open(\"results/\"+DATASET+\"_\"+MODEL+\"_results.pkl\", \"wb\") as f:\n",
    "    pkl.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the properties\n",
    "with open(\"results/\"+DATASET+\"_\"+MODEL+\"_results.pkl\", \"rb\") as f:\n",
    "    results = pkl.load(f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "('x8', 'num_nodes')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [26], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j, embedding \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(embeddings):\n\u001b[1;32m     14\u001b[0m     name_of_embedding \u001b[38;5;241m=\u001b[39m embeddings_names[j]\n\u001b[0;32m---> 15\u001b[0m     test_r2 \u001b[38;5;241m=\u001b[39m \u001b[43mresults\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_of_embedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproperty_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;241m3\u001b[39m]\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m test_r2 \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.05\u001b[39m:  \u001b[38;5;66;03m# Handle negative R² values\u001b[39;00m\n\u001b[1;32m     17\u001b[0m         test_r2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.05\u001b[39m\n",
      "\u001b[0;31mKeyError\u001b[0m: ('x8', 'num_nodes')"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming results, embeddings, and other necessary variables are defined as in your context\n",
    "# property_names = ['num_nodes', 'num_edges', 'density', 'avg_path_len', 'num_cliques', 'num_triangles', 'num_squares', 'number_of_nodes_in_the_largest_fully_connected_component']\n",
    "# embeddings_names = ['x', 'x2', 'x3', 'x4', 'x5', 'x_global', 'x6', 'x7', 'x8']\n",
    "colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k', 'w', 'orange', 'red']\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for i, property_name in enumerate(property_names):\n",
    "    x_points = []\n",
    "    y_points = []\n",
    "    for j, embedding in enumerate(embeddings):\n",
    "        name_of_embedding = embeddings_names[j]\n",
    "        test_r2 = results[(name_of_embedding, property_name)][3]\n",
    "        if test_r2 < -0.05:  # Handle negative R² values\n",
    "            test_r2 = -0.05\n",
    "        x_points.append(j)\n",
    "        y_points.append(test_r2)\n",
    "    \n",
    "    # Plotting the line for the current property\n",
    "    plt.plot(x_points, y_points, label=property_name, color=colors[i], marker='x')\n",
    "\n",
    "plt.xticks(range(len(embeddings)), embeddings_names)\n",
    "plt.xlabel('Embedding')\n",
    "plt.ylabel('R²')\n",
    "plt.legend()\n",
    "plt.title('FC matrice - GCN - R² for different embeddings and properties')\n",
    "plt.show()\n",
    "\n",
    "#save the plot\n",
    "plt.savefig(\"results/\"+DATASET+\"_\"+MODEL+\"test_R2_plot.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [28], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m y_points \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j, embedding \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(embeddings):\n\u001b[0;32m---> 14\u001b[0m     name_of_embedding \u001b[38;5;241m=\u001b[39m \u001b[43membeddings_names\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     15\u001b[0m     train_r2 \u001b[38;5;241m=\u001b[39m results[(name_of_embedding, property_name)][\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m train_r2 \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.05\u001b[39m:\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming results, embeddings, and other necessary variables are defined as in your context\n",
    "property_names = ['num_nodes', 'num_edges', 'density', 'avg_path_len', 'num_cliques', 'num_triangles', 'num_squares', 'number_of_nodes_in_the_largest_fully_connected_component']\n",
    "embeddings_names = ['x1', 'x2', 'x3', 'x4', 'x5', 'x_global', 'x6', 'x7']#, 'x8']\n",
    "colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k', 'w', 'orange', 'red']\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for i, property_name in enumerate(property_names):\n",
    "    x_points = []\n",
    "    y_points = []\n",
    "    for j, embedding in enumerate(embeddings):\n",
    "        name_of_embedding = embeddings_names[j]\n",
    "        train_r2 = results[(name_of_embedding, property_name)][2]\n",
    "        if train_r2 < -0.05:\n",
    "            train_r2 = -0.05\n",
    "        x_points.append(j)\n",
    "        y_points.append(train_r2)\n",
    "\n",
    "    # Plotting the line for the current property\n",
    "    plt.plot(x_points, y_points, label=property_name, color=colors[i], marker='x')\n",
    "\n",
    "plt.xticks(range(len(embeddings)), embeddings_names)\n",
    "plt.xlabel('Embedding')\n",
    "plt.ylabel('R²')\n",
    "plt.legend()\n",
    "plt.title('FC matrice - GCN - R² for different embeddings and properties')\n",
    "plt.show()\n",
    "\n",
    "#save the plot\n",
    "plt.savefig(\"results/\"+DATASET+\"_\"+MODEL+\"train_R2_plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('x1', 'num_nodes'): (4.3371153,\n",
       "  7.853936,\n",
       "  -1.2496113777160645,\n",
       "  -7.9182281494140625),\n",
       " ('x1', 'num_edges'): (20337.445,\n",
       "  20424.877,\n",
       "  0.04202932119369507,\n",
       "  -0.13952815532684326),\n",
       " ('x1', 'density'): (0.0004103724,\n",
       "  0.0004617122,\n",
       "  0.10539329051971436,\n",
       "  -0.15323865413665771),\n",
       " ('x1', 'avg_path_len'): (0.23916489,\n",
       "  0.5176885,\n",
       "  0.11239689588546753,\n",
       "  -0.7487330436706543),\n",
       " ('x1', 'num_cliques'): (946.1469,\n",
       "  765.57996,\n",
       "  0.11579090356826782,\n",
       "  0.002257823944091797),\n",
       " ('x1', 'num_triangles'): (564190.06,\n",
       "  467938.2,\n",
       "  0.02725958824157715,\n",
       "  -0.0580286979675293),\n",
       " ('x1', 'num_squares'): (1.5593792,\n",
       "  2.158648,\n",
       "  0.1003313660621643,\n",
       "  -0.4620513916015625),\n",
       " ('x1', 'number_of_nodes_in_the_largest_fully_connected_component'): (8.767505,\n",
       "  9.757291,\n",
       "  -0.2536911964416504,\n",
       "  -2.238513231277466),\n",
       " ('x2', 'num_nodes'): (3.359905,\n",
       "  49.32192,\n",
       "  -0.7427436113357544,\n",
       "  -55.00556564331055),\n",
       " ('x2', 'num_edges'): (20213.604,\n",
       "  56144.69,\n",
       "  0.047862708568573,\n",
       "  -2.1323788166046143),\n",
       " ('x2', 'density'): (0.000408822,\n",
       "  0.0005072819,\n",
       "  0.1087731122970581,\n",
       "  -0.2670600414276123),\n",
       " ('x2', 'avg_path_len'): (0.24126019,\n",
       "  0.38153484,\n",
       "  0.10462063550949097,\n",
       "  -0.28881096839904785),\n",
       " ('x2', 'num_cliques'): (938.1318,\n",
       "  1264.4454,\n",
       "  0.12328135967254639,\n",
       "  -0.6478886604309082),\n",
       " ('x2', 'num_triangles'): (575604.2,\n",
       "  493594.22,\n",
       "  0.0075800418853759766,\n",
       "  -0.11603808403015137),\n",
       " ('x2', 'num_squares'): (1.5296663,\n",
       "  1.6345974,\n",
       "  0.11747390031814575,\n",
       "  -0.10711205005645752),\n",
       " ('x2', 'number_of_nodes_in_the_largest_fully_connected_component'): (7.651761,\n",
       "  35.935505,\n",
       "  -0.0941476821899414,\n",
       "  -10.92724609375),\n",
       " ('x3', 'num_nodes'): (2.7219214,\n",
       "  412.2808,\n",
       "  -0.4118291139602661,\n",
       "  -467.1492614746094),\n",
       " ('x3', 'num_edges'): (21080.658,\n",
       "  150599.03,\n",
       "  0.007021069526672363,\n",
       "  -7.402098655700684),\n",
       " ('x3', 'density'): (0.00040245082,\n",
       "  0.0019710548,\n",
       "  0.12266218662261963,\n",
       "  -3.923189163208008),\n",
       " ('x3', 'avg_path_len'): (0.23936413,\n",
       "  2.7024496,\n",
       "  0.11165744066238403,\n",
       "  -8.128776550292969),\n",
       " ('x3', 'num_cliques'): (944.68945,\n",
       "  4154.5215,\n",
       "  0.11715292930603027,\n",
       "  -4.414380073547363),\n",
       " ('x3', 'num_triangles'): (592117.6,\n",
       "  531497.4,\n",
       "  -0.020891427993774414,\n",
       "  -0.20173871517181396),\n",
       " ('x3', 'num_squares'): (1.5437075,\n",
       "  4.351046,\n",
       "  0.10937303304672241,\n",
       "  -1.9469618797302246),\n",
       " ('x3', 'number_of_nodes_in_the_largest_fully_connected_component'): (7.058432,\n",
       "  409.30527,\n",
       "  -0.009305834770202637,\n",
       "  -134.85128784179688),\n",
       " ('x4', 'num_nodes'): (2.127435,\n",
       "  36.86699,\n",
       "  -0.10347580909729004,\n",
       "  -40.862857818603516),\n",
       " ('x4', 'num_edges'): (21527.26,\n",
       "  21562.494,\n",
       "  -0.014015555381774902,\n",
       "  -0.202997088432312),\n",
       " ('x4', 'density'): (0.00040105064,\n",
       "  0.002765891,\n",
       "  0.12571454048156738,\n",
       "  -5.908486366271973),\n",
       " ('x4', 'avg_path_len'): (0.24110167,\n",
       "  5.7197733,\n",
       "  0.10520893335342407,\n",
       "  -18.32118797302246),\n",
       " ('x4', 'num_cliques'): (964.11664,\n",
       "  811.3316,\n",
       "  0.09899759292602539,\n",
       "  -0.05736804008483887),\n",
       " ('x4', 'num_triangles'): (587049.0,\n",
       "  470619.25,\n",
       "  -0.012152433395385742,\n",
       "  -0.06409060955047607),\n",
       " ('x4', 'num_squares'): (1.5299855,\n",
       "  4.3065076,\n",
       "  0.1172897219657898,\n",
       "  -1.9167957305908203),\n",
       " ('x4',\n",
       "  'number_of_nodes_in_the_largest_fully_connected_component'): (6.7394433, 38.609764, 0.03630727529525757, -11.814851760864258),\n",
       " ('x5', 'num_nodes'): (2.7497053,\n",
       "  8.207253,\n",
       "  -0.4262402057647705,\n",
       "  -8.319424629211426),\n",
       " ('x5', 'num_edges'): (10625.011,\n",
       "  15162.388,\n",
       "  0.49952173233032227,\n",
       "  0.15407240390777588),\n",
       " ('x5', 'density'): (1.6989918e-05,\n",
       "  3.876389e-05,\n",
       "  0.9629622101783752,\n",
       "  0.9031777381896973),\n",
       " ('x5', 'avg_path_len'): (0.07137861,\n",
       "  0.15940505,\n",
       "  0.7350953817367554,\n",
       "  0.4615355134010315),\n",
       " ('x5', 'num_cliques'): (411.99628,\n",
       "  682.07294,\n",
       "  0.614974319934845,\n",
       "  0.11108839511871338),\n",
       " ('x5', 'num_triangles'): (262517.03,\n",
       "  314000.47,\n",
       "  0.5473849177360535,\n",
       "  0.29003119468688965),\n",
       " ('x5', 'num_squares'): (0.6976407,\n",
       "  0.8223699,\n",
       "  0.5975029468536377,\n",
       "  0.44300925731658936),\n",
       " ('x5',\n",
       "  'number_of_nodes_in_the_largest_fully_connected_component'): (6.5502434, 15.577017, 0.0633615255355835, -4.170121192932129),\n",
       " ('x_global', 'num_nodes'): (1.3923762,\n",
       "  2.5177615,\n",
       "  0.2777906060218811,\n",
       "  -1.8589451313018799),\n",
       " ('x_global', 'num_edges'): (7338.1226,\n",
       "  10744.28,\n",
       "  0.6543465852737427,\n",
       "  0.4005638360977173),\n",
       " ('x_global', 'density'): (1.8581834e-05,\n",
       "  3.799404e-05,\n",
       "  0.9594918489456177,\n",
       "  0.9051006436347961),\n",
       " ('x_global', 'avg_path_len'): (0.074279465,\n",
       "  0.11876068,\n",
       "  0.7243295907974243,\n",
       "  0.5988306999206543),\n",
       " ('x_global', 'num_cliques'): (357.379,\n",
       "  523.2062,\n",
       "  0.666016161441803,\n",
       "  0.3181315064430237),\n",
       " ('x_global', 'num_triangles'): (328305.16,\n",
       "  313270.75,\n",
       "  0.43395721912384033,\n",
       "  0.29168111085891724),\n",
       " ('x_global', 'num_squares'): (0.71051455,\n",
       "  0.7900029,\n",
       "  0.5900756120681763,\n",
       "  0.4649313688278198),\n",
       " ('x_global',\n",
       "  'number_of_nodes_in_the_largest_fully_connected_component'): (4.738928, 5.444331, 0.3223668932914734, -0.807011604309082),\n",
       " ('x6', 'num_nodes'): (2.8568568,\n",
       "  89.42436,\n",
       "  -0.4818185567855835,\n",
       "  -100.54232025146484),\n",
       " ('x6', 'num_edges'): (6639.1685,\n",
       "  17153.887,\n",
       "  0.6872700452804565,\n",
       "  0.042964279651641846),\n",
       " ('x6', 'density'): (3.9390172e-05,\n",
       "  0.00030337085,\n",
       "  0.914129912853241,\n",
       "  0.24225741624832153),\n",
       " ('x6', 'avg_path_len'): (0.0944737,\n",
       "  0.5525237,\n",
       "  0.649383544921875,\n",
       "  -0.8664050102233887),\n",
       " ('x6', 'num_cliques'): (396.16235,\n",
       "  877.71515,\n",
       "  0.6297717094421387,\n",
       "  -0.14388227462768555),\n",
       " ('x6', 'num_triangles'): (198502.98,\n",
       "  345741.25,\n",
       "  0.6577538251876831,\n",
       "  0.21826398372650146),\n",
       " ('x6', 'num_squares'): (0.7462854,\n",
       "  1.3409884,\n",
       "  0.5694379210472107,\n",
       "  0.09174907207489014),\n",
       " ('x6', 'number_of_nodes_in_the_largest_fully_connected_component'): (6.389413,\n",
       "  92.80305,\n",
       "  0.08635920286178589,\n",
       "  -29.80198097229004),\n",
       " ('x7', 'num_nodes'): (173.02892,\n",
       "  55.71213,\n",
       "  -88.74809265136719,\n",
       "  -62.261722564697266),\n",
       " ('x7', 'num_edges'): (181588.56,\n",
       "  193358.75,\n",
       "  -7.553509712219238,\n",
       "  -9.787714004516602),\n",
       " ('x7', 'density'): (0.00039908072,\n",
       "  0.00035553222,\n",
       "  0.13000893592834473,\n",
       "  0.11197167634963989),\n",
       " ('x7', 'avg_path_len'): (0.26440486,\n",
       "  0.29447106,\n",
       "  0.018724799156188965,\n",
       "  0.005287468433380127),\n",
       " ('x7', 'num_cliques'): (2933.5513,\n",
       "  2437.8179,\n",
       "  -1.741511583328247,\n",
       "  -2.177086353302002),\n",
       " ('x7', 'num_triangles'): (1447425.1,\n",
       "  1451311.8,\n",
       "  -1.4955577850341797,\n",
       "  -2.2814791202545166),\n",
       " ('x7', 'num_squares'): (1.5731655,\n",
       "  1.4393548,\n",
       "  0.09237754344940186,\n",
       "  0.025125622749328613),\n",
       " ('x7',\n",
       "  'number_of_nodes_in_the_largest_fully_connected_component'): (169.23555, 53.779327, -23.199485778808594, -16.8497371673584)}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test with more properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "def calculate_avg_path_length(G):\n",
    "    if nx.is_connected(G):\n",
    "        return nx.average_shortest_path_length(G)\n",
    "    else:\n",
    "        # Use the average path length of the largest connected component for disconnected graphs\n",
    "        components = [G.subgraph(c).copy() for c in nx.connected_components(G)]\n",
    "        largest_component = max(components, key=len)\n",
    "        return nx.average_shortest_path_length(largest_component)\n",
    "    \n",
    "def betweenness_centralization(G):\n",
    "    n = len(G)\n",
    "    betweenness = nx.betweenness_centrality(G)\n",
    "    max_betweenness = max(betweenness.values())\n",
    "    centralization = sum(max_betweenness - bet for bet in betweenness.values())\n",
    "    if n > 2:\n",
    "        centralization /= (n - 1) * (n - 2) / 2\n",
    "    return centralization\n",
    "\n",
    "def pagerank_centralization(G, alpha=0.85):\n",
    "    n = len(G)\n",
    "    pagerank = nx.pagerank(G, alpha=alpha)\n",
    "    max_pagerank = max(pagerank.values())\n",
    "    centralization = sum(max_pagerank - pr for pr in pagerank.values())\n",
    "    if n > 1:\n",
    "        centralization /= (n - 1)\n",
    "    return centralization\n",
    "\n",
    "def clustering_properties(G):\n",
    "    average_clustering = nx.average_clustering(G)\n",
    "    transitivity = nx.transitivity(G)\n",
    "    return average_clustering, transitivity\n",
    "\n",
    "def compute_graph_properties(data):\n",
    "    properties = []\n",
    "    for graph_data in data:\n",
    "        G = nx.from_edgelist(graph_data.edge_index.t().tolist())\n",
    "        \n",
    "        # Number of nodes\n",
    "        num_nodes = G.number_of_nodes()\n",
    "        \n",
    "        # Number of edges\n",
    "        num_edges = G.number_of_edges()\n",
    "        \n",
    "        # Density\n",
    "        density = nx.density(G)\n",
    "        \n",
    "        # Average Path Length\n",
    "        avg_path_len = calculate_avg_path_length(G)\n",
    "        \n",
    "        # Diameter\n",
    "        if nx.is_connected(G):\n",
    "            diameter = nx.diameter(G)\n",
    "        else:\n",
    "            # Use the diameter of the largest connected component for disconnected graphs\n",
    "            components = [G.subgraph(c).copy() for c in nx.connected_components(G)]\n",
    "            largest_component = max(components, key=len)\n",
    "            diameter = nx.diameter(largest_component)\n",
    "        \n",
    "        # Radius\n",
    "        if nx.is_connected(G):\n",
    "            radius = nx.radius(G)\n",
    "        else:\n",
    "            radius = nx.radius(largest_component)\n",
    "        \n",
    "        # Clustering Coefficient\n",
    "        clustering_coeff = nx.average_clustering(G)\n",
    "        \n",
    "        # Transitivity\n",
    "        transitivity = nx.transitivity(G)\n",
    "        \n",
    "        # Assortativity\n",
    "        assortativity = nx.degree_assortativity_coefficient(G)\n",
    "        \n",
    "        # Number of Cliques\n",
    "        num_cliques = len(list(nx.find_cliques(G)))\n",
    "        \n",
    "        # Number of Triangles\n",
    "        num_triangles = sum(nx.triangles(G).values()) / 3\n",
    "        \n",
    "        # Number of Squares (4-cycles)\n",
    "        num_squares = sum(nx.square_clustering(G).values()) / 4\n",
    "        \n",
    "        # Size of the Largest Connected Component\n",
    "        largest_component_size = len(max(nx.connected_components(G), key=len))\n",
    "        \n",
    "        # Average Degree\n",
    "        degrees = [d for n, d in G.degree()]\n",
    "        avg_degree = np.mean(degrees)\n",
    "        \n",
    "        # Betweenness Centrality\n",
    "        betweenness_centrality = nx.betweenness_centrality(G)\n",
    "        avg_betweenness_centrality = np.mean(list(betweenness_centrality.values()))\n",
    "        \n",
    "        # Eigenvalues of the Adjacency Matrix (for spectral properties)\n",
    "        eigenvalues = np.linalg.eigvals(nx.adjacency_matrix(G).todense())\n",
    "        spectral_radius = max(eigenvalues)\n",
    "        algebraic_connectivity = sorted(eigenvalues)[1]  # second smallest eigenvalue\n",
    "        \n",
    "        # Graph Laplacian Eigenvalues\n",
    "        laplacian_eigenvalues = np.linalg.eigvals(nx.laplacian_matrix(G).todense())\n",
    "        graph_energy = sum(abs(laplacian_eigenvalues))\n",
    "        \n",
    "        # Small-World-ness\n",
    "        # Compare clustering coefficient and average path length with those of a random graph\n",
    "        random_graph = nx.gnm_random_graph(num_nodes, num_edges)\n",
    "        random_clustering_coeff = nx.average_clustering(random_graph)\n",
    "        random_avg_path_len = calculate_avg_path_length(random_graph)\n",
    "        small_world_coefficient = (clustering_coeff / random_clustering_coeff) / (avg_path_len / random_avg_path_len)\n",
    "\n",
    "        # Calculate Betweenness Centralization\n",
    "        betweenness_cent = betweenness_centralization(G)\n",
    "        print(f\"Betweenness Centralization: {betweenness_cent}\")\n",
    "\n",
    "        # Calculate PageRank Centralization\n",
    "        pagerank_cent = pagerank_centralization(G)\n",
    "        print(f\"PageRank Centralization: {pagerank_cent}\")\n",
    "\n",
    "        # Calculate Clustering properties\n",
    "        avg_clustering, transitivity = clustering_properties(G)\n",
    "        print(f\"Average Clustering Coefficient: {avg_clustering}\")\n",
    "        print(f\"Transitivity: {transitivity}\")\n",
    "        \n",
    "        properties.append((\n",
    "            num_nodes,\n",
    "            num_edges,\n",
    "            density,\n",
    "            avg_path_len,\n",
    "            diameter,\n",
    "            radius,\n",
    "            clustering_coeff,\n",
    "            transitivity,\n",
    "            assortativity,\n",
    "            num_cliques,\n",
    "            num_triangles,\n",
    "            num_squares,\n",
    "            largest_component_size,\n",
    "            avg_degree,\n",
    "            avg_betweenness_centrality,\n",
    "            spectral_radius,\n",
    "            algebraic_connectivity,\n",
    "            graph_energy,\n",
    "            small_world_coefficient\n",
    "        ))\n",
    "    return properties\n",
    "\n",
    "\n",
    "train_idx_list = gnn.train_idx.tolist()\n",
    "selected_dataset = [gnn.dataset[i] for i in train_idx_list]\n",
    "train_properties_long = compute_graph_properties(selected_dataset)\n",
    "test_idx_list = gnn.test_idx.tolist()\n",
    "selected_dataset = [gnn.dataset[i] for i in test_idx_list]\n",
    "test_properties_long = compute_graph_properties(selected_dataset)\n",
    "\n",
    "#save the properties in a file\n",
    "with open(\"results/\"+DATASET+\"_\"+MODEL+\"_train_properties_long.pkl\", \"wb\") as f:\n",
    "    pkl.dump(train_properties_long, f)\n",
    "\n",
    "with open(\"results/\"+DATASET+\"_\"+MODEL+\"_test_properties_long.pkl\", \"wb\") as f:\n",
    "    pkl.dump(test_properties_long, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the properties\n",
    "with open(\"results/\"+DATASET+\"_\"+MODEL+\"_train_properties_long.pkl\", \"rb\") as f:\n",
    "    train_properties_long = pkl.load(f)\n",
    "\n",
    "with open(\"results/\"+DATASET+\"_\"+MODEL+\"_test_properties_long.pkl\", \"rb\") as f:\n",
    "    test_properties_long = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "property_names_long = ['num_nodes', 'num_edges', 'density', 'avg_path_len', 'diameter', 'radius', 'clustering_coeff', 'transitivity', 'assortativity', 'num_cliques', 'num_triangles', 'num_squares', 'largest_component_size', 'avg_degree', 'avg_betweenness_centrality', 'spectral_radius', 'algebraic_connectivity', 'graph_energy', 'small_world_coefficient']\n",
    "train_y_long = torch.tensor(train_properties_long, dtype=torch.float32)\n",
    "test_y_long = torch.tensor(test_properties_long, dtype=torch.float32)\n",
    "#create a dictionary where we will store the results for each embeddings, each property\n",
    "results = {}\n",
    "\n",
    "ii = 0\n",
    "\n",
    "for train_embedding, test_embedding in embeddings:\n",
    "    input_size = train_embedding.shape[1]\n",
    "\n",
    "    for i, property_name in enumerate(property_names_long):\n",
    "        model = LinearModel(input_size, output_size)\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "        num_epochs = 800000  # Maximum number of epochs\n",
    "        min_epochs = 1000  # Minimum number of epochs\n",
    "        patience = 3000  # Number of epochs to wait for improvement\n",
    "        tolerance = 1e-6  # Tolerance for considering the loss as stable\n",
    "\n",
    "        best_loss = float('inf')\n",
    "        no_improve_count = 0\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(train_embedding).squeeze()\n",
    "            target = train_y_long[:, i].squeeze()\n",
    "\n",
    "            loss = criterion(outputs, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (epoch+1) % 1000 == 0:  # Print every 1000 epochs\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}], Property: {property_name}, Loss: {loss.item():.4f}')\n",
    "\n",
    "            # Check for early stopping, but only after minimum epochs\n",
    "            if epoch >= min_epochs:\n",
    "                if loss.item() < best_loss - tolerance:\n",
    "                    best_loss = loss.item()\n",
    "                    no_improve_count = 0\n",
    "                else:\n",
    "                    no_improve_count += 1\n",
    "\n",
    "                if no_improve_count >= patience:\n",
    "                    print(f'Early stopping at epoch {epoch+1}')\n",
    "                    break\n",
    "\n",
    "        # Evaluate the model\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            train_pred = model(train_embedding).squeeze().cpu().numpy()\n",
    "            test_pred = model(test_embedding).squeeze().cpu().numpy()\n",
    "\n",
    "            train_target = train_y_long[:, i].cpu().numpy()\n",
    "            test_target = test_y_long[:, i].cpu().numpy()\n",
    "\n",
    "            train_mse = mean_squared_error(train_target, train_pred)\n",
    "            test_mse = mean_squared_error(test_target, test_pred)\n",
    "\n",
    "            train_r2 = r2_score(train_target, train_pred)\n",
    "            test_r2 = r2_score(test_target, test_pred)\n",
    "\n",
    "            print(f'Embedding: {train_embedding.shape}')\n",
    "            print(f'Property: {property_name}')\n",
    "            print(f'  Train MSE: {train_mse:.4f}, Test MSE: {test_mse:.4f}')\n",
    "            print(f'  Train R²: {train_r2:.4f}, Test R²: {test_r2:.4f}')\n",
    "\n",
    "            #add the results to the dictionary\n",
    "            name_of_embedding = embeddings_names[ii]\n",
    "            results[(name_of_embedding, property_name)] = (train_mse, test_mse, train_r2, test_r2)\n",
    "\n",
    "    ii += 1\n",
    "\n",
    "#save results\n",
    "with open(\"results/\"+DATASET+\"_\"+MODEL+\"_results_limited_cv_long.pkl\", \"wb\") as f:\n",
    "    pkl.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results/\"+DATASET+\"_\"+MODEL+\"_results_limited_cv_long.pkl\", \"rb\") as f:\n",
    "    results = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "colors_long = [\n",
    "    (0.0, 0.45, 0.70),  # Blue\n",
    "    (0.85, 0.37, 0.01),  # Orange\n",
    "    (0.8, 0.47, 0.74),   # Magenta\n",
    "    (0.0, 0.62, 0.45),   # Green\n",
    "    (0.95, 0.90, 0.25),  # Yellow\n",
    "    (0.9, 0.6, 0.0),     # Brown\n",
    "    (0.35, 0.7, 0.9),    # Sky Blue\n",
    "    (0.8, 0.6, 0.7),     # Light Pink\n",
    "    (0.3, 0.3, 0.3),     # Dark Gray\n",
    "    (0.5, 0.5, 0.0),     # Olive\n",
    "    (0.0, 0.75, 0.75),   # Cyan\n",
    "    (0.6, 0.6, 0.6),     # Light Gray\n",
    "    (0.7, 0.3, 0.1),     # Dark Orange\n",
    "    (0.6, 0.2, 0.5),     # Purple\n",
    "    (0.9, 0.4, 0.3),     # Salmon\n",
    "    (0.4, 0.4, 0.8),     # Light Blue\n",
    "    (0.2, 0.8, 0.2),     # Light Green\n",
    "    (0.6, 0.6, 0.3),     # Mustard\n",
    "    (0.3, 0.55, 0.55)    # Teal\n",
    "]\n",
    "\n",
    "property_names_long = ['num_nodes', 'num_edges', 'density', 'avg_path_len', 'diameter', 'radius', 'clustering_coeff', 'transitivity', 'assortativity', 'num_cliques', 'num_triangles', 'num_squares', 'largest_component_size', 'avg_degree', 'avg_betweenness_centrality', 'spectral_radius', 'algebraic_connectivity', 'graph_energy', 'small_world_coefficient']\n",
    "embeddings_names = ['x1', 'x2', 'x3', 'x4', 'x5', 'x_global', 'x6', 'x7', 'x8']\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for i, property_names_long in enumerate(property_names_long):\n",
    "    x_points = []\n",
    "    y_points = []\n",
    "    for j, embedding in enumerate(embeddings):\n",
    "        name_of_embedding = embeddings_names[j]\n",
    "        test_r2 = results[(name_of_embedding, property_names_long)][3]\n",
    "        if test_r2 < -0.05:  # Handle negative R² values\n",
    "            test_r2 = -0.05\n",
    "        x_points.append(j)\n",
    "        y_points.append(test_r2)\n",
    "    \n",
    "    # Plotting the line for the current property\n",
    "    plt.plot(x_points, y_points, label=property_names_long, color=colors_long[i], marker='x')\n",
    "\n",
    "plt.xticks(range(len(embeddings)), embeddings_names)\n",
    "plt.xlabel('Embedding')\n",
    "plt.ylabel('R²')\n",
    "plt.legend()\n",
    "plt.title('FC matrice - GCN - R² for different embeddings and properties')\n",
    "plt.show()\n",
    "\n",
    "#save the plot\n",
    "plt.savefig('results/'+DATASET+'_'+MODEL+'test_R2_plot_long.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range(len(embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "property_names_long = ['num_nodes', 'num_edges', 'density', 'avg_path_len', 'diameter', 'radius', 'clustering_coeff', 'transitivity', 'assortativity', 'num_cliques', 'num_triangles', 'num_squares', 'largest_component_size', 'avg_degree', 'avg_betweenness_centrality', 'spectral_radius', 'algebraic_connectivity', 'graph_energy', 'small_world_coefficient']\n",
    "\n",
    "for i, property_names_long in enumerate(property_names_long):\n",
    "    x_points = []\n",
    "    y_points = []\n",
    "    for j, embedding in enumerate(embeddings):\n",
    "        name_of_embedding = embeddings_names[j]\n",
    "        train_r2 = results[(name_of_embedding, property_names_long)][2]\n",
    "        if train_r2 < -0.05:  # Handle negative R² values\n",
    "            train_r2 = -0.05\n",
    "        x_points.append(j)\n",
    "        y_points.append(train_r2)\n",
    "\n",
    "    # Plotting the line for the current property\n",
    "    plt.plot(x_points, y_points, label=property_names_long, color=colors_long[i], marker='x')\n",
    "\n",
    "plt.xticks(range(len(embeddings)), embeddings_names)\n",
    "plt.xlabel('Embedding')\n",
    "plt.ylabel('R²')\n",
    "plt.legend()\n",
    "plt.title('FC matrice - GCN - R² for different embeddings and properties')\n",
    "plt.show()\n",
    "\n",
    "#save the plot\n",
    "plt.savefig('results/'+DATASET+'_'+MODEL+'train_R2_plot_long.png')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
