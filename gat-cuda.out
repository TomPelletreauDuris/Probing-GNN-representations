/home/tpelletreaudur/.local/lib/python3.10/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
INFO:root:Model loaded from: models/BA_2grid_house_with_node_degree_as_features_and_expand_10_dimensions_GAT
INFO:root:Train Loss: 0.050, Train Acc: 0.988, Test Loss: 0.097, Test Acc: 0.968
Net(
  (conv1): GATConv(10, 128, heads=8)
  (conv2): GATConv(1024, 128, heads=8)
  (conv3): GATConv(1024, 128, heads=8)
  (lin1): Linear(in_features=1024, out_features=20, bias=True)
  (lin2): Linear(in_features=20, out_features=2, bias=True)
)
tensor([ 701, 1225,   47,  ...,   40,  423,  494])
BA_2grid_house_with_node_degree_as_features_and_expand_10_dimensions(1600)
we loaded the weights
Traceback (most recent call last):
  File "/gpfs/home3/tpelletreaudur/Probing-GNN-representations/Probing_GAT.py", line 169, in <module>
    train_features = reindex_graph_embeddings(train_features)
  File "/gpfs/home3/tpelletreaudur/Probing-GNN-representations/Probing_GAT.py", line 159, in reindex_graph_embeddings
    norms = torch.norm(layer_tensor, dim=1)
  File "/sw/arch/RHEL8/EB_production/2022/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/functional.py", line 1472, in norm
    return _VF.frobenius_norm(input, _dim, keepdim=keepdim)
IndexError: Dimension out of range (expected to be in range of [-1, 0], but got 1)

JOB STATISTICS
==============
Job ID: 8012963
Cluster: snellius
User/Group: tpelletreaudur/tpelletreaudur
State: FAILED (exit code 1)
Nodes: 1
Cores per node: 16
CPU Utilized: 01:35:40
CPU Efficiency: 83.24% of 01:54:56 core-walltime
Job Wall-clock time: 00:07:11
Memory Utilized: 1.10 GB
Memory Efficiency: 3.95% of 28.00 GB
