{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fd324b6c",
   "metadata": {},
   "source": [
    "# Load a model\n",
    "\n",
    "Each model has been developed within a class in the folder models. The name of the \n",
    "module represent the name of the dataset. The model contains a class for each architecture.\n",
    "The constructor of the calss build the model, split the dataset and set all the hyperparameters of the networks.\n",
    "So the reproducibility is achived by only instanziating the model.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a41401ae",
   "metadata": {},
   "source": [
    "First you have to chose a model and a dataset.  \n",
    "\n",
    "for instacne: GIN on the GRID dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff519fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"GIN\"\n",
    "DATASET = \"BA_2grid_house\"\n",
    "\n",
    "# import the model\n",
    "from models.models_BA_2grid_house import GIN_framework as framework\n",
    "# import the dataset\n",
    "from Datasets.synthetics import BA_2grid_house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e84082",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomdu\\OneDrive\\Documents\\ENSC_VU\\4A-Vu\\Thesis\\Probing GNN\\ProbingVenv\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# inizialize the framework\n",
    "dataset = BA_2grid_house()\n",
    "gnn = framework(dataset,device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55734e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (mlp1): Linear(in_features=10, out_features=30, bias=True)\n",
      "  (conv1): GINConv(nn=Linear(in_features=10, out_features=30, bias=True))\n",
      "  (mlp2): Linear(in_features=30, out_features=30, bias=True)\n",
      "  (conv2): GINConv(nn=Linear(in_features=30, out_features=30, bias=True))\n",
      "  (lin1): Linear(in_features=30, out_features=30, bias=True)\n",
      "  (lin2): Linear(in_features=30, out_features=2, bias=True)\n",
      ")\n",
      "tensor([ 701, 1225,   47,  ...,   40,  423,  494])\n",
      "BA_2grid_house(1600)\n"
     ]
    }
   ],
   "source": [
    "# the gnn object contains the train test split and the model.\n",
    "\n",
    "print(gnn.model)\n",
    "print(gnn.train_idx)\n",
    "print(gnn.dataset[gnn.train_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e019ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1212, -0.0306,  0.2503,  0.0236, -0.1754,  0.0293,  0.2900,  0.2228,\n",
      "        -0.2381, -0.1020], dtype=torch.float64, grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# right now the model has random weights.\n",
    "print(gnn.model.mlp1.weight[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df452016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we loaded the weights\n",
      "tensor([-0.1264, -0.0357,  0.2452,  0.0184, -0.1806,  0.0242,  0.2849,  0.2177,\n",
      "        -0.2432, -0.1072], dtype=torch.float64, grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#now that the model is instaziated, we have to load the weights\n",
    "gnn.load_model(\"models/\"+DATASET+\"_\"+MODEL)\n",
    "print(\"we loaded the weights\")\n",
    "# right now the model has trained weights.\n",
    "print(gnn.model.mlp1.weight[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29673448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.035, Train Acc: 0.971 Test Acc: 0.973\n"
     ]
    }
   ],
   "source": [
    "# we also have a build in function to evaluate the model\n",
    "gnn.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb46bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also train the model for 20 epochs\n",
    "gnn.train() #gnn.train()\n",
    "\n",
    "for i in range(20):\n",
    "    gnn.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71909c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.035, Train Acc: 0.971 Test Acc: 0.973\n"
     ]
    }
   ],
   "source": [
    "gnn.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d273b142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved in:  models/BA_2grid_house_GIN\n"
     ]
    }
   ],
   "source": [
    "#save\n",
    "gnn.save_model(\"models/\"+DATASET+\"_\"+MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475c1ce3",
   "metadata": {},
   "source": [
    "### GAT on grid-house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7c633a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"BA_2grid_house_with_node_degree_as_features_and_expand_10_dimensions\"\n",
    "MODEL = \"GAT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bec71d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): GATConv(10, 128, heads=8)\n",
      "  (conv2): GATConv(1024, 128, heads=8)\n",
      "  (conv3): GATConv(1024, 128, heads=8)\n",
      "  (lin1): Linear(in_features=1024, out_features=20, bias=True)\n",
      "  (lin2): Linear(in_features=20, out_features=2, bias=True)\n",
      ")\n",
      "tensor([ 701, 1225,   47,  ...,   40,  423,  494])\n",
      "BA_2grid_house_with_node_degree_as_features_and_expand_10_dimensions(1600)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomdu\\OneDrive\\Documents\\ENSC_VU\\4A-Vu\\Thesis\\Probing GNN\\ProbingVenv\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from models.models_BA_2grid_house import GAT_Framework_5 as GAT_framework\n",
    "from Datasets.synthetics import BA_2grid_house_with_node_degree_as_features_and_expand_10_dimensions\n",
    "\n",
    "# inizialize the framework\n",
    "dataset = BA_2grid_house_with_node_degree_as_features_and_expand_10_dimensions()\n",
    "gnn = GAT_framework(dataset,device=\"cpu\")\n",
    "\n",
    "# the gnn object contains the train test split and the model.\n",
    "\n",
    "print(gnn.model)\n",
    "print(gnn.train_idx)\n",
    "print(gnn.dataset[gnn.train_idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eba5e4df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6942403936386108"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnn.train() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff72a7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 020, Loss: 0.538, Train Loss: 0.553, Train Acc: 0.734, Test Loss: 0.603, Test Acc: 0.710\n",
      "INFO:root:Epoch: 040, Loss: 0.497, Train Loss: 0.416, Train Acc: 0.807, Test Loss: 0.451, Test Acc: 0.792\n",
      "INFO:root:Epoch: 060, Loss: 0.234, Train Loss: 0.193, Train Acc: 0.921, Test Loss: 0.237, Test Acc: 0.902\n",
      "INFO:root:Epoch: 080, Loss: 0.176, Train Loss: 0.211, Train Acc: 0.916, Test Loss: 0.214, Test Acc: 0.915\n",
      "INFO:root:Epoch: 100, Loss: 0.066, Train Loss: 0.067, Train Acc: 0.983, Test Loss: 0.109, Test Acc: 0.963\n",
      "INFO:root:Epoch: 120, Loss: 0.047, Train Loss: 0.050, Train Acc: 0.988, Test Loss: 0.097, Test Acc: 0.968\n"
     ]
    }
   ],
   "source": [
    "#let's train the model\n",
    "gnn.iterate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56db2985",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Train Loss: 0.050, Train Acc: 0.988, Test Loss: 0.097, Test Acc: 0.968\n"
     ]
    }
   ],
   "source": [
    "gnn.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "244d5b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Model saved in: models/BA_2grid_house_with_node_degree_as_features_and_expand_10_dimensions_GAT\n"
     ]
    }
   ],
   "source": [
    "# we can also save the model\n",
    "\n",
    "gnn.save_model(\"models/\"+DATASET+\"_\"+MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbea933e",
   "metadata": {},
   "source": [
    "### Gat 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee16304e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"BA_2grid_house\"\n",
    "MODEL = \"GAT3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "234863fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): GATv2Conv(10, 10, heads=1)\n",
      "  (conv2): GATv2Conv(10, 20, heads=1)\n",
      "  (conv3): GATv2Conv(20, 10, heads=1)\n",
      "  (lin1): Linear(in_features=10, out_features=20, bias=True)\n",
      "  (lin2): Linear(in_features=20, out_features=2, bias=True)\n",
      ")\n",
      "tensor([ 701, 1225,   47,  ...,   40,  423,  494])\n",
      "BA_2grid_house(1600)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomdu\\OneDrive\\Documents\\ENSC_VU\\4A-Vu\\Thesis\\Probing GNN\\ProbingVenv\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from models.models_BA_2grid_house import GATV2Framework\n",
    "from Datasets.synthetics import BA_2grid_house\n",
    "\n",
    "# inizialize the framework\n",
    "dataset = BA_2grid_house()\n",
    "gnn = GATV2Framework(dataset,device=\"cpu\")\n",
    "\n",
    "# the gnn object contains the train test split and the model.\n",
    "\n",
    "print(gnn.model)\n",
    "print(gnn.train_idx)\n",
    "print(gnn.dataset[gnn.train_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a5d9d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.693176969145371"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's train the model\n",
    "gnn.train()\n",
    "#gnn.iterate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32c6945d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Train Loss: 0.693, Train Acc: 0.500, Test Loss: 0.693, Test Acc: 0.500\n"
     ]
    }
   ],
   "source": [
    "gnn.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6bc970",
   "metadata": {},
   "source": [
    "Using the code to train and load GAT for the GRID dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66fd16fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): GATConv(10, 30, heads=1)\n",
      "  (conv2): GATConv(30, 30, heads=1)\n",
      "  (conv3): GATConv(30, 30, heads=1)\n",
      "  (lin1): Linear(in_features=30, out_features=10, bias=True)\n",
      "  (lin2): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n",
      "tensor([ 701, 1225,   47,  ...,   40,  423,  494])\n",
      "BA_2grid(1600)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomdu\\OneDrive\\Documents\\ENSC_VU\\4A-Vu\\Thesis\\Probing GNN\\ProbingVenv\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from models.models_BA_2grid import GAT2_framework\n",
    "from Datasets.synthetics import BA_2grid\n",
    "\n",
    "# inizialize the framework\n",
    "dataset = BA_2grid()\n",
    "gnn = GAT2_framework(dataset,device=\"cpu\")\n",
    "\n",
    "# the gnn object contains the train test split and the model.\n",
    "\n",
    "print(gnn.model)\n",
    "print(gnn.train_idx)\n",
    "print(gnn.dataset[gnn.train_idx])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb5069bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 020, Loss: 0.693, Test Loss: 0.173, Train Acc: 0.500 Test Acc: 0.500\n",
      "Epoch: 040, Loss: 0.693, Test Loss: 0.173, Train Acc: 0.500 Test Acc: 0.500\n",
      "Epoch: 060, Loss: 0.693, Test Loss: 0.173, Train Acc: 0.500 Test Acc: 0.500\n",
      "Epoch: 080, Loss: 0.693, Test Loss: 0.173, Train Acc: 0.500 Test Acc: 0.500\n",
      "Epoch: 100, Loss: 0.693, Test Loss: 0.173, Train Acc: 0.500 Test Acc: 0.500\n",
      "Epoch: 120, Loss: 0.693, Test Loss: 0.173, Train Acc: 0.500 Test Acc: 0.500\n",
      "Epoch: 140, Loss: 0.693, Test Loss: 0.173, Train Acc: 0.500 Test Acc: 0.500\n",
      "Epoch: 160, Loss: 0.693, Test Loss: 0.173, Train Acc: 0.500 Test Acc: 0.500\n",
      "Epoch: 180, Loss: 0.693, Test Loss: 0.173, Train Acc: 0.500 Test Acc: 0.500\n",
      "Epoch: 200, Loss: 0.693, Test Loss: 0.173, Train Acc: 0.500 Test Acc: 0.500\n",
      "Epoch: 220, Loss: 0.693, Test Loss: 0.173, Train Acc: 0.500 Test Acc: 0.500\n",
      "Epoch: 240, Loss: 0.693, Test Loss: 0.173, Train Acc: 0.500 Test Acc: 0.500\n",
      "Epoch: 260, Loss: 0.693, Test Loss: 0.173, Train Acc: 0.500 Test Acc: 0.500\n",
      "Epoch: 280, Loss: 0.693, Test Loss: 0.173, Train Acc: 0.500 Test Acc: 0.500\n",
      "Epoch: 300, Loss: 0.693, Test Loss: 0.173, Train Acc: 0.500 Test Acc: 0.500\n",
      "Epoch: 320, Loss: 0.693, Test Loss: 0.173, Train Acc: 0.500 Test Acc: 0.500\n",
      "Epoch: 340, Loss: 0.693, Test Loss: 0.173, Train Acc: 0.500 Test Acc: 0.500\n",
      "Epoch: 360, Loss: 0.693, Test Loss: 0.173, Train Acc: 0.500 Test Acc: 0.500\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#let's train the model\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mgnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tomdu\\OneDrive\\Documents\\ENSC_VU\\4A-Vu\\Thesis\\Probing GNN\\models\\models_BA_2grid.py:319\u001b[0m, in \u001b[0;36mGAT2_framework.iterate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21miterate\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3001\u001b[39m):\n\u001b[1;32m--> 319\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    320\u001b[0m         train_acc,train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader)\n\u001b[0;32m    321\u001b[0m         test_acc,test_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_loader)\n",
      "File \u001b[1;32mc:\\Users\\tomdu\\OneDrive\\Documents\\ENSC_VU\\4A-Vu\\Thesis\\Probing GNN\\models\\models_BA_2grid.py:295\u001b[0m, in \u001b[0;36mGAT2_framework.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    293\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(data\u001b[38;5;241m.\u001b[39mx, data\u001b[38;5;241m.\u001b[39medge_index, data\u001b[38;5;241m.\u001b[39mbatch)\n\u001b[0;32m    294\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mnll_loss(output, data\u001b[38;5;241m.\u001b[39my\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m--> 295\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m    297\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(loss) \u001b[38;5;241m*\u001b[39m data\u001b[38;5;241m.\u001b[39mnum_graphs\n",
      "File \u001b[1;32mc:\\Users\\tomdu\\OneDrive\\Documents\\ENSC_VU\\4A-Vu\\Thesis\\Probing GNN\\ProbingVenv\\lib\\site-packages\\torch\\_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    524\u001b[0m     )\n\u001b[1;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tomdu\\OneDrive\\Documents\\ENSC_VU\\4A-Vu\\Thesis\\Probing GNN\\ProbingVenv\\lib\\site-packages\\torch\\autograd\\__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tomdu\\OneDrive\\Documents\\ENSC_VU\\4A-Vu\\Thesis\\Probing GNN\\ProbingVenv\\lib\\site-packages\\torch\\autograd\\graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    745\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    746\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#let's train the model\n",
    "\n",
    "gnn.iterate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b752f827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.173, Train Acc: 0.500 Test Acc: 0.500\n"
     ]
    }
   ],
   "source": [
    "gnn.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3aecb0c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DATASET' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# we can also save the model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m gnn\u001b[38;5;241m.\u001b[39msave_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[43mDATASET\u001b[49m\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mMODEL)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DATASET' is not defined"
     ]
    }
   ],
   "source": [
    "# we can also save the model\n",
    "gnn.save_model(\"models/\"+DATASET+\"_\"+MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6354b94",
   "metadata": {},
   "source": [
    "GAT on grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843b93b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"grid\"\n",
    "MODEL = \"GAT\"\n",
    "\n",
    "from models.models_BA_2grid import GAT_framework\n",
    "from Datasets.grid import Grid\n",
    "\n",
    "# Initialize the framework\n",
    "dataset = Grid()\n",
    "gnn = GAT_framework(dataset, device=\"cpu\")\n",
    "\n",
    "# The gnn object contains the train test split and the model.\n",
    "print(gnn.model)\n",
    "print(gnn.train_idx)\n",
    "print(gnn.dataset[gnn.train_idx])\n",
    "\n",
    "# Train the model\n",
    "gnn.train()\n",
    "\n",
    "# Evaluate the model\n",
    "gnn.evaluate()\n",
    "\n",
    "# Save the model\n",
    "gnn.save_model(\"models/\" + DATASET + \"_\" + MODEL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38161c7",
   "metadata": {},
   "source": [
    "# RGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb0e5bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomdu\\OneDrive\\Documents\\ENSC_VU\\4A-Vu\\Thesis\\Probing GNN\\ProbingVenv\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): RGCNConv(10, 30, num_relations=2)\n",
      "  (conv2): RGCNConv(30, 30, num_relations=2)\n",
      "  (lin1): Linear(in_features=30, out_features=30, bias=True)\n",
      "  (lin2): Linear(in_features=30, out_features=2, bias=True)\n",
      ")\n",
      "tensor([ 701, 1225,   47,  ...,   40,  423,  494])\n",
      "BA_2grid_house_with_node_degree_as_features_and_expand_10_dimensions(1600)\n"
     ]
    }
   ],
   "source": [
    "MODEL = \"RGCN\"\n",
    "DATASET = \"BA_2grid_house\"\n",
    "\n",
    "# import the model\n",
    "from models.models_BA_2grid_house import RGCN_framework as framework\n",
    "# import the dataset\n",
    "from Datasets.synthetics import BA_2grid_house_with_node_degree_as_features_and_expand_10_dimensions\n",
    "# inizialize the framework\n",
    "dataset = BA_2grid_house_with_node_degree_as_features_and_expand_10_dimensions()\n",
    "gnn = framework(dataset,device=\"cpu\")\n",
    "# the gnn object contains the train test split and the model.\n",
    "\n",
    "print(gnn.model)\n",
    "print(gnn.train_idx)\n",
    "print(gnn.dataset[gnn.train_idx])\n",
    "# right now the model has random weights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75bf3ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 020, Loss: 0.476, Train Loss: 0.470, Train Acc: 0.766, Test Loss: 0.510, Test Acc: 0.728\n",
      "INFO:root:Epoch: 040, Loss: 0.415, Train Loss: 0.410, Train Acc: 0.796, Test Loss: 0.442, Test Acc: 0.775\n",
      "INFO:root:Epoch: 060, Loss: 0.397, Train Loss: 0.391, Train Acc: 0.798, Test Loss: 0.424, Test Acc: 0.782\n",
      "INFO:root:Epoch: 080, Loss: 0.386, Train Loss: 0.380, Train Acc: 0.809, Test Loss: 0.414, Test Acc: 0.785\n",
      "INFO:root:Epoch: 100, Loss: 0.378, Train Loss: 0.373, Train Acc: 0.811, Test Loss: 0.409, Test Acc: 0.795\n",
      "INFO:root:Epoch: 120, Loss: 0.371, Train Loss: 0.365, Train Acc: 0.824, Test Loss: 0.402, Test Acc: 0.805\n",
      "INFO:root:Epoch: 140, Loss: 0.367, Train Loss: 0.361, Train Acc: 0.829, Test Loss: 0.400, Test Acc: 0.805\n",
      "INFO:root:Epoch: 160, Loss: 0.363, Train Loss: 0.357, Train Acc: 0.830, Test Loss: 0.398, Test Acc: 0.805\n",
      "INFO:root:Epoch: 180, Loss: 0.359, Train Loss: 0.352, Train Acc: 0.831, Test Loss: 0.396, Test Acc: 0.800\n",
      "INFO:root:Epoch: 200, Loss: 0.354, Train Loss: 0.348, Train Acc: 0.832, Test Loss: 0.395, Test Acc: 0.807\n",
      "INFO:root:Epoch: 220, Loss: 0.352, Train Loss: 0.346, Train Acc: 0.841, Test Loss: 0.398, Test Acc: 0.805\n",
      "INFO:root:Epoch: 240, Loss: 0.348, Train Loss: 0.343, Train Acc: 0.839, Test Loss: 0.396, Test Acc: 0.810\n",
      "INFO:root:Epoch: 260, Loss: 0.347, Train Loss: 0.341, Train Acc: 0.843, Test Loss: 0.397, Test Acc: 0.805\n",
      "INFO:root:Epoch: 280, Loss: 0.343, Train Loss: 0.338, Train Acc: 0.840, Test Loss: 0.395, Test Acc: 0.807\n",
      "INFO:root:Epoch: 300, Loss: 0.341, Train Loss: 0.336, Train Acc: 0.839, Test Loss: 0.394, Test Acc: 0.812\n",
      "INFO:root:Epoch: 320, Loss: 0.339, Train Loss: 0.333, Train Acc: 0.835, Test Loss: 0.393, Test Acc: 0.810\n",
      "INFO:root:Epoch: 340, Loss: 0.337, Train Loss: 0.331, Train Acc: 0.835, Test Loss: 0.391, Test Acc: 0.812\n",
      "INFO:root:Epoch: 360, Loss: 0.334, Train Loss: 0.328, Train Acc: 0.833, Test Loss: 0.389, Test Acc: 0.815\n",
      "INFO:root:Epoch: 380, Loss: 0.326, Train Loss: 0.322, Train Acc: 0.833, Test Loss: 0.380, Test Acc: 0.818\n",
      "INFO:root:Epoch: 400, Loss: 0.327, Train Loss: 0.322, Train Acc: 0.833, Test Loss: 0.380, Test Acc: 0.810\n",
      "INFO:root:Epoch: 420, Loss: 0.326, Train Loss: 0.321, Train Acc: 0.834, Test Loss: 0.378, Test Acc: 0.810\n",
      "INFO:root:Epoch: 440, Loss: 0.318, Train Loss: 0.311, Train Acc: 0.839, Test Loss: 0.374, Test Acc: 0.818\n",
      "INFO:root:Epoch: 460, Loss: 0.315, Train Loss: 0.313, Train Acc: 0.844, Test Loss: 0.372, Test Acc: 0.810\n",
      "INFO:root:Epoch: 480, Loss: 0.312, Train Loss: 0.308, Train Acc: 0.844, Test Loss: 0.372, Test Acc: 0.815\n",
      "INFO:root:Epoch: 500, Loss: 0.306, Train Loss: 0.303, Train Acc: 0.846, Test Loss: 0.368, Test Acc: 0.823\n"
     ]
    }
   ],
   "source": [
    "gnn.iterate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47480598",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Model saved in: models/BA_2grid_house_RGCN\n"
     ]
    }
   ],
   "source": [
    "#save\n",
    "gnn.save_model(\"models/\"+DATASET+\"_\"+MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "660b6970",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Model loaded from: models/BA_2grid_house_RGCN\n",
      "INFO:root:Train Loss: 0.303, Train Acc: 0.846, Test Loss: 0.368, Test Acc: 0.823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we loaded the weights\n"
     ]
    }
   ],
   "source": [
    "#now that the model is instaziated, we have to load the weights\n",
    "gnn.load_model(\"models/\"+DATASET+\"_\"+MODEL)\n",
    "print(\"we loaded the weights\")\n",
    "# right now the model has trained weights.\n",
    "gnn.evaluate()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
