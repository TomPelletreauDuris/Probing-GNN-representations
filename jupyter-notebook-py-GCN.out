GPU available? True
545.23.08
Python 3.10.4
/gpfs/home3/tpelletreaudur/Probing-GNN-representations/FC_probing_GCN.py:943: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  y = np.array([data.y for data in dataset])
/gpfs/home3/tpelletreaudur/Probing-GNN-representations/FC_probing_GCN.py:943: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  y = np.array([data.y for data in dataset])
/home/tpelletreaudur/.local/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/tpelletreaudur/.local/lib/python3.10/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found
  warnings.warn(message)
[tensor([0]) tensor([0]) tensor([0]) ... tensor([0]) tensor([0])
 tensor([0])]
[0 1 1 ... 0 0 0]
Traceback (most recent call last):
  File "/gpfs/home3/tpelletreaudur/Probing-GNN-representations/FC_probing_GCN.py", line 974, in <module>
    gnn.iterate()
  File "/gpfs/home3/tpelletreaudur/Probing-GNN-representations/models/models_FC.py", line 248, in iterate
    loss = self.train()
  File "/gpfs/home3/tpelletreaudur/Probing-GNN-representations/models/models_FC.py", line 224, in train
    output = self.model(data.x, data.edge_index, data.batch)
  File "/sw/arch/RHEL8/EB_production/2022/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/gpfs/home3/tpelletreaudur/Probing-GNN-representations/models/models_FC.py", line 193, in forward
    x = F.relu(self.bn1(self.lin1(x_global)))
  File "/sw/arch/RHEL8/EB_production/2022/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/tpelletreaudur/.local/lib/python3.10/site-packages/torch_geometric/nn/norm/batch_norm.py", line 88, in forward
    return self.module(x)
  File "/sw/arch/RHEL8/EB_production/2022/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/sw/arch/RHEL8/EB_production/2022/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py", line 168, in forward
    return F.batch_norm(
  File "/sw/arch/RHEL8/EB_production/2022/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/nn/functional.py", line 2436, in batch_norm
    _verify_batch_size(input.size())
  File "/sw/arch/RHEL8/EB_production/2022/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/nn/functional.py", line 2404, in _verify_batch_size
    raise ValueError("Expected more than 1 value per channel when training, got input size {}".format(size))
ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 128])

JOB STATISTICS
==============
Job ID: 7664935
Cluster: snellius
User/Group: tpelletreaudur/tpelletreaudur
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:01
CPU Efficiency: 0.21% of 00:08:06 core-walltime
Job Wall-clock time: 00:00:27
Memory Utilized: 2.81 MB
Memory Efficiency: 0.00% of 120.00 GB
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
